<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="GenAI Bench Team" /><link rel="canonical" href="https://github.com/sgl-project/genai-bench/user-guide/run-benchmark-using-docker/" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>Run Benchmark with Docker - GenAI Bench</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Run Benchmark with Docker";
        var mkdocs_page_input_path = "user-guide/run-benchmark-using-docker.md";
        var mkdocs_page_url = "/sgl-project/genai-bench/user-guide/run-benchmark-using-docker/";
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/yaml.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/python.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/bash.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/json.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> GenAI Bench
        </a>
        <div class="version">
          1.0.0
        </div><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Getting Started</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../getting-started/installation/">Installation</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../getting-started/task-definition/">Task Definition</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../getting-started/command-guidelines/">Command Guidelines</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../getting-started/metrics-definition/">Metrics Definition</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">User Guide</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../run-benchmark/">Run Benchmark</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">Run Benchmark with Docker</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#using-pre-built-docker-image">Using Pre-built Docker Image</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#building-from-source">Building from Source</a>
    </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../generate-excel-sheet/">Generate Excel Sheet</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../generate-plot/">Generate Plot</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../upload-benchmark-result/">Upload Benchmark Results</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Examples</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../examples/%20plot-config-examples/">Plot Config Examples</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Development</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../development/contributing/">Contributing</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">GenAI Bench</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">User Guide</li>
      <li class="breadcrumb-item active">Run Benchmark with Docker</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/sgl-project/genai-bench/edit/main/docs/user-guide/run-benchmark-using-docker.md">Edit on sgl-project/genai-bench</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="running-benchmark-using-genai-bench-container"><a class="toclink" href="#running-benchmark-using-genai-bench-container">Running Benchmark Using <code>genai-bench</code> Container</a><a class="headerlink" href="#running-benchmark-using-genai-bench-container" title="Permanent link">&para;</a></h1>
<h2 id="using-pre-built-docker-image"><a class="toclink" href="#using-pre-built-docker-image">Using Pre-built Docker Image</a><a class="headerlink" href="#using-pre-built-docker-image" title="Permanent link">&para;</a></h2>
<p>Pull the latest docker image:</p>
<div class="codehilite"><pre><span></span><code>docker<span class="w"> </span>pull<span class="w"> </span>ghcr.io/moirai-internal/genai-bench:v0.0.1
</code></pre></div>

<h2 id="building-from-source"><a class="toclink" href="#building-from-source">Building from Source</a><a class="headerlink" href="#building-from-source" title="Permanent link">&para;</a></h2>
<p>Alternatively, you can build the image locally from the <a href="https://github.com/sgl-project/genai-bench/blob/main/Dockerfile">Dockerfile</a>:</p>
<div class="codehilite"><pre><span></span><code>docker<span class="w"> </span>build<span class="w"> </span>.<span class="w"> </span>-f<span class="w"> </span>Dockerfile<span class="w"> </span>-t<span class="w"> </span>genai-bench:dev
</code></pre></div>

<p>To avoid internet disruptions and network latency, it's recommended to run the benchmarking within the same network as the target inference server. You can always choose to use <code>--network host</code> if you prefer.</p>
<p>To create a bridge network in docker:</p>
<div class="codehilite"><pre><span></span><code>docker<span class="w"> </span>network<span class="w"> </span>create<span class="w"> </span>benchmark-network<span class="w"> </span>-d<span class="w"> </span>bridge
</code></pre></div>

<p>Then, start the inference server using the standard Docker command with the additional flag <code>--network benchmark-network</code>.</p>
<p><strong>Example:</strong></p>
<div class="codehilite"><pre><span></span><code>docker<span class="w"> </span>run<span class="w"> </span>-itd<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--gpus<span class="w"> </span><span class="se">\&quot;</span><span class="nv">device</span><span class="o">=</span><span class="m">0</span>,1,2,3<span class="se">\&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--shm-size<span class="w"> </span>10g<span class="w">  </span>-v<span class="w"> </span>/raid/models:/models<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--ulimit<span class="w"> </span><span class="nv">nofile</span><span class="o">=</span><span class="m">65535</span>:65535<span class="w">   </span>--network<span class="w"> </span>benchmark-network<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--name<span class="w"> </span>sglang-v0.4.7.post1-llama4-scout-tp4<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>lmsysorg/sglang:v0.4.7.post1-cu124<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>python3<span class="w"> </span>-m<span class="w"> </span>sglang.launch_server<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model-path<span class="o">=</span>/models/meta-llama/Llama-4-Scout-17B-16E-Instruct<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--tp<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--port<span class="o">=</span><span class="m">8080</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--host<span class="w"> </span><span class="m">0</span>.0.0.0<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--context-length<span class="o">=</span><span class="m">131072</span>
</code></pre></div>

<p>Next, start the genai-bench container with the same network flag.</p>
<p><strong>Example:</strong></p>
<p>First, create a dataset configuration file to properly specify the split:</p>
<p><strong>llava-config.json:</strong></p>
<div class="codehilite"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;source&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;huggingface&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;lmms-lab/llava-bench-in-the-wild&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;huggingface_kwargs&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;split&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;train&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;prompt_column&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;question&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;image_column&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;image&quot;</span>
<span class="p">}</span>
</code></pre></div>

<p>Then run the benchmark with the configuration file:</p>
<div class="codehilite"><pre><span></span><code>docker<span class="w"> </span>run<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-tid<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--shm-size<span class="w"> </span>5g<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--ulimit<span class="w"> </span><span class="nv">nofile</span><span class="o">=</span><span class="m">65535</span>:65535<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--env<span class="w"> </span><span class="nv">HF_TOKEN</span><span class="o">=</span><span class="s2">&quot;your_HF_TOKEN&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--network<span class="w"> </span>benchmark-network<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-v<span class="w"> </span>/mnt/data/models:/models<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-v<span class="w"> </span><span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>/llava-config.json:/genai-bench/llava-config.json<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--name<span class="w"> </span>llama-4-scout-benchmark<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>genai-bench:dev<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>benchmark<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--api-backend<span class="w"> </span>openai<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--api-base<span class="w"> </span>http://localhost:8080<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--api-key<span class="w"> </span>your_api_key<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--api-model-name<span class="w"> </span>/models/meta-llama/Llama-4-Scout-17B-16E-Instruct<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model-tokenizer<span class="w"> </span>/models/meta-llama/Llama-4-Scout-17B-16E-Instruct<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--task<span class="w"> </span>image-to-text<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max-time-per-run<span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max-requests-per-run<span class="w"> </span><span class="m">100</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--server-engine<span class="w"> </span><span class="s2">&quot;SGLang&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--server-gpu-type<span class="w"> </span><span class="s2">&quot;H100&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--server-version<span class="w"> </span><span class="s2">&quot;v0.4.7.post1&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--server-gpu-count<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--traffic-scenario<span class="w"> </span><span class="s2">&quot;I(512,512)&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--traffic-scenario<span class="w"> </span><span class="s2">&quot;I(2048,2048)&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num-concurrency<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num-concurrency<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num-concurrency<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset-config<span class="w"> </span>/genai-bench/llava-config.json
</code></pre></div>

<p>Note that <code>genai-bench</code> is already the entrypoint of the container, so you only need to provide the command arguments afterward.</p>
<p>The genai-bench runtime UI should be available through:</p>
<div class="codehilite"><pre><span></span><code>docker<span class="w"> </span>logs<span class="w"> </span>--follow<span class="w"> </span>&lt;CONTAINER_ID&gt;
</code></pre></div>

<p>You can also utilize <code>tmux</code> for additional parallelism and session control.</p>
<h1 id="monitor-benchmark-using-volume-mount"><a class="toclink" href="#monitor-benchmark-using-volume-mount">Monitor benchmark using volume mount</a><a class="headerlink" href="#monitor-benchmark-using-volume-mount" title="Permanent link">&para;</a></h1>
<p>To monitor benchmark interim results using the genai-bench container, you can leverage volume mounts along with the <code>--experiment-base-dir</code> option.</p>
<div class="codehilite"><pre><span></span><code><span class="nv">HOST_OUTPUT_DIR</span><span class="o">=</span><span class="nv">$HOME</span>/benchmark_results
<span class="nv">CONTAINER_OUTPUT_DIR</span><span class="o">=</span>/genai-bench/benchmark_results
docker<span class="w"> </span>run<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-tid<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--shm-size<span class="w"> </span>5g<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--ulimit<span class="w"> </span><span class="nv">nofile</span><span class="o">=</span><span class="m">65535</span>:65535<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--env<span class="w"> </span><span class="nv">HF_TOKEN</span><span class="o">=</span><span class="s2">&quot;your_HF_TOKEN&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--network<span class="w"> </span>benchmark-network<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-v<span class="w"> </span>/mnt/data/models:/models<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-v<span class="w"> </span><span class="nv">$HOST_OUTPUT_DIR</span>:<span class="nv">$CONTAINER_OUTPUT_DIR</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-v<span class="w"> </span><span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>/llava-config.json:/genai-bench/llava-config.json<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--name<span class="w"> </span>llama-3.2-11b-benchmark<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>genai-bench:dev<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>benchmark<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--api-backend<span class="w"> </span>openai<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--api-base<span class="w"> </span>http://localhost:8080<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--api-key<span class="w"> </span>your_api_key<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--api-model-name<span class="w"> </span>/models/meta-llama/Llama-4-Scout-17B-16E-Instruct<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model-tokenizer<span class="w"> </span>/models/meta-llama/Llama-4-Scout-17B-16E-Instruct<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--task<span class="w"> </span>image-to-text<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max-time-per-run<span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max-requests-per-run<span class="w"> </span><span class="m">100</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--server-engine<span class="w"> </span><span class="s2">&quot;SGLang&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--server-gpu-type<span class="w"> </span><span class="s2">&quot;H100&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--server-version<span class="w"> </span><span class="s2">&quot;v0.4.7.post1&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--server-gpu-count<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--traffic-scenario<span class="w"> </span><span class="s2">&quot;I(512,512)&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--traffic-scenario<span class="w"> </span><span class="s2">&quot;I(2048,2048)&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num-concurrency<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num-concurrency<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num-concurrency<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset-config<span class="w"> </span>/genai-bench/llava-config.json<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--experiment-base-dir<span class="w"> </span><span class="nv">$CONTAINER_OUTPUT_DIR</span>
</code></pre></div>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../run-benchmark/" class="btn btn-neutral float-left" title="Run Benchmark"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../generate-excel-sheet/" class="btn btn-neutral float-right" title="Generate Excel Sheet">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
      <p>Copyright &copy; 2024 GenAI Bench Team</p>
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/sgl-project/genai-bench" class="fa fa-code-fork" style="color: #fcfcfc"> sgl-project/genai-bench</a>
        </span>
    
    
      <span><a href="../run-benchmark/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../generate-excel-sheet/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../..";</script>
    <script src="../../js/theme_extra.js"></script>
    <script src="../../js/theme.js"></script>
      <script src="../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
